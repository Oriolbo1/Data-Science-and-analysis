{"cells":[{"cell_type":"markdown","source":["# Caso práctico de Analítica Escalable (Ejercicios) #"],"metadata":{}},{"cell_type":"markdown","source":["En este notebook, se van a realizar los ejercicios del módulo. En lugar de tener contenido teórico y descripciones, se dejarán únicamente las celdas de código necesarias para su ejecución.\n\nPara completar los ejercicios, hay que codificar y ejecutar la solución en las celdas que se encuentran justo debajo de los enunciados de los ejercicios.\n\nUna vez se haya terminado, en el menú de la izquiera, a la hora de seleccionar el notebook, si se le hace click a la flecha que se encuentra en la derecha, se puede exportar al notebook. Hay que exportarlo en formato DBC (Databricks Notebook) como en HTML."],"metadata":{}},{"cell_type":"code","source":["print(sc.version)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2.4.5\n</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["Los ejercicios consistirán en añadir nuevas funcionalidades, o ejecutar nuevo código, sobre el Notebook que contiene toda la teoría vista en el módulo. Por ello, gran parte del código que se encuentra dentro del notebook de contenido teórico se encontrará aquí de nuevo, pero se pedirá nuevo código."],"metadata":{}},{"cell_type":"markdown","source":["## Importando los datos ##"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.cp(\"/FileStore/tables/Hotel_Reviews.csv\", \"file:///databricks/driver/Hotel_Reviews.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: True</div>"]}}],"execution_count":6},{"cell_type":"code","source":["def score_to_string(score):\n  if score < 5:\n    return \"Bad\"\n  elif score < 7:\n    return \"Normal\"\n  elif score < 9:\n    return \"Good\"\n  elif score < 10: \n    return \"Excellent\"\n  else:\n    return \"Perfect\"\n  \ndef score_to_evaluation(score_string):\n  score_dict = {\n    \"Bad\": 0,\n    \"Normal\": 1,\n    \"Good\": 2,\n    \"Excellent\": 3,\n    \"Perfect\": 4\n  }\n  return score_dict.get(score_string, None)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## DataFrames en Spark: SparkSQL. ##"],"metadata":{}},{"cell_type":"code","source":["df_spark_sql = spark.read.format(\"csv\")\\\n         .option(\"header\", \"true\")\\\n         .option(\"inferSchema\", \"true\")\\\n         .load(\"/FileStore/tables/Hotel_Reviews.csv\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["from pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType, IntegerType\n\nscore_string_udf = udf(score_to_string, StringType())\nscore_evaluation_udf = udf(score_to_evaluation, IntegerType())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["df_spark_sql = df_spark_sql.withColumn('score_string',score_string_udf(df_spark_sql[\"Average_Score\"]))\ndf_spark_sql = df_spark_sql.withColumn('score_evaluation',score_evaluation_udf(df_spark_sql[\"score_string\"]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["def day_to_int(day):\n  return int(day.replace(\" days\", \"\").replace(\" day\", \"\"))\nday_to_int_udf = udf(day_to_int, IntegerType())\ndf_spark_sql = df_spark_sql.withColumn(\"days_since_review\", day_to_int_udf(df_spark_sql[\"days_since_review\"]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["### Ejercicio 1: Crear un bucle que muestre todas las columnas del DataFrame, junto con sus tipos. También puedes pintar el esquema del Dataframe. ###\n\nVoy a empezar creando un bucle con for \"i\" in df_spark_sql.dtypes e imprimiendo \"i\" en cada iteración. De esta forma nos imprime la información que contiene, en este caso el nombre de la columna y su tipo.\n\nA continuación voy a usar el codigo \"df_spark_sql.printSchema()\" para obtener el esquema del dataframe."],"metadata":{}},{"cell_type":"code","source":["\nprint(\"----tipos de datos----\")\nfor i in df_spark_sql.dtypes:\n  print(i)\n  \nprint(\"\\n\"*3)\nprint(\"----Esquema----\")\ndf_spark_sql.printSchema()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">----tipos de datos----\n(&#39;Hotel_Address&#39;, &#39;string&#39;)\n(&#39;Additional_Number_of_Scoring&#39;, &#39;int&#39;)\n(&#39;Review_Date&#39;, &#39;string&#39;)\n(&#39;Average_Score&#39;, &#39;double&#39;)\n(&#39;Hotel_Name&#39;, &#39;string&#39;)\n(&#39;Reviewer_Nationality&#39;, &#39;string&#39;)\n(&#39;Negative_Review&#39;, &#39;string&#39;)\n(&#39;Review_Total_Negative_Word_Counts&#39;, &#39;int&#39;)\n(&#39;Total_Number_of_Reviews&#39;, &#39;int&#39;)\n(&#39;Positive_Review&#39;, &#39;string&#39;)\n(&#39;Review_Total_Positive_Word_Counts&#39;, &#39;int&#39;)\n(&#39;Total_Number_of_Reviews_Reviewer_Has_Given&#39;, &#39;int&#39;)\n(&#39;Reviewer_Score&#39;, &#39;double&#39;)\n(&#39;Tags&#39;, &#39;string&#39;)\n(&#39;days_since_review&#39;, &#39;int&#39;)\n(&#39;lat&#39;, &#39;float&#39;)\n(&#39;lng&#39;, &#39;float&#39;)\n(&#39;score_string&#39;, &#39;string&#39;)\n(&#39;score_evaluation&#39;, &#39;int&#39;)\n\n\n\n\n----Esquema----\nroot\n-- Hotel_Address: string (nullable = true)\n-- Additional_Number_of_Scoring: integer (nullable = true)\n-- Review_Date: string (nullable = true)\n-- Average_Score: double (nullable = true)\n-- Hotel_Name: string (nullable = true)\n-- Reviewer_Nationality: string (nullable = true)\n-- Negative_Review: string (nullable = true)\n-- Review_Total_Negative_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews: integer (nullable = true)\n-- Positive_Review: string (nullable = true)\n-- Review_Total_Positive_Word_Counts: integer (nullable = true)\n-- Total_Number_of_Reviews_Reviewer_Has_Given: integer (nullable = true)\n-- Reviewer_Score: double (nullable = true)\n-- Tags: string (nullable = true)\n-- days_since_review: integer (nullable = true)\n-- lat: float (nullable = true)\n-- lng: float (nullable = true)\n-- score_string: string (nullable = true)\n-- score_evaluation: integer (nullable = true)\n\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["### Ejercicio 2: Realizar un muestreo de 10 valores únicos de nombres de hoteles. Ordénalos alfanuméricamente de forma ascendente (primero los números 0-9, después A-Z). ###\n\nEmpiezo seleccionando la columna 'Hotel_Name'. A continuación le digo que solo seleccione los valores únicos. Posteriormente limito el numero de resultados a 10 y finalizo ordenando los resultados."],"metadata":{}},{"cell_type":"code","source":["df_spark_sql.select('Hotel_Name').distinct().limit(10).orderBy('Hotel_Name').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\n          Hotel_Name|\n+--------------------+\n      Avenida Palace|\nBest Western Sera...|\nGrange Holborn Hotel|\nH tel Barri re Le...|\nH tel Elysees Mermoz|\n H10 Port Vell 4 Sup|\n         HCC Regente|\nHyatt Regency Ams...|\nMelia Paris Notre...|\nMelia Paris Tour ...|\n+--------------------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["### Ejercicio 3: Transforma las columnas *lat* y *lng* al tipo Float.\n\nEmpiezo convirtiendo la columna \"lat\". Para dicha finalidad utilizo la función \"witColumn\" que crea una nueva columna,no obstante, dado que el nombre de la \"nueva\" columna es el mismo que una columna ya existente en el dataframe, la función usada lo que hará será sustituir la columna que figurava en el dataframe. \n\nA continuación hago referéncia a la columna 'df_spark_sql[\"lat\"]' y termino diciendole que quiero que se convierta en tipo \"Float\". \n\nTermino aplicando el mismo procedimiento a la columna \"lng\""],"metadata":{}},{"cell_type":"code","source":["df_spark_sql = df_spark_sql.withColumn(\"lat\", df_spark_sql[\"lat\"].cast(\"Float\"))\ndf_spark_sql = df_spark_sql.withColumn(\"lng\", df_spark_sql[\"lng\"].cast(\"Float\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["splits = df_spark_sql.randomSplit([0.67, 0.33])\ndf_spark_sql_train = splits[0].dropna()\ndf_spark_sql_test = splits[1].dropna()\nprint(df_spark_sql_train.count())\nprint(df_spark_sql_test.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">342967\n169503\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["### Ejercicio 4: ¿Cuántos hoteles tienen una puntuación de 'Perfect'? ¿Y 'Good'? ¿Y 'Normal' junto a 'Good'? (Utilizar el dataset de Train)\n\nVoy a empezar el ejercicio filtrando las filas de la columna \"score_string\" que contengan la palabra \"Perfect\". Como se puede ver, no hay ningún registro y esto lo compruebo con el comando \"distinct\". No figura ninguna entrada como \"Perfect\". \n\nA continuación aplico el mimso codigo para los registros en que figure la palabra \"Good\" y finalizo realizando lo mismo para \"Normal\" y \"Good\"."],"metadata":{}},{"cell_type":"code","source":["print(\"Puntuación 'Perfect'\")\nprint(df_spark_sql_train.filter('score_string=\"Perfect\"').count()) #no hay ninguno\ndf_spark_sql_train.select('score_string').distinct().show() #lo compruebo con el comando \"distinct\" y veo que efectivamente no hay ninguna valoración \"Perfect\"\nprint(\"\\n\",\"Puntuación 'Good'\")\nprint(df_spark_sql_train.filter('score_string=\"Good\"').count())\nprint(\"\\n\",\"Puntuación 'Good'+'Normal'\")\nprint(df_spark_sql_train.filter('(score_string = \"Normal\") or (score_string = \"Good\")').count())\n     "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Puntuación &#39;Perfect&#39;\n0\n+------------+\nscore_string|\n+------------+\n   Excellent|\n        Good|\n      Normal|\n+------------+\n\n\n Puntuación &#39;Good&#39;\n285831\n\n Puntuación &#39;Good&#39;+&#39;Normal&#39;\n289583\n</div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["### Ejercicio 5: Obtener los hoteles con mayor puntuación media, descartando todos los que tengan una puntuación por encima de Good. (Utilizar el dataset de Train) ###\n\nPara hacer este ejercicio he empezado qutando las puntuaciones superiores a \"Good\" (\"Perfect\" y \"Excellent\"). \nSeguidamente he seleccionado las columnas que quería visualizar ('Hotel_Name',\"Average_Score\"). \nA continuación he agrupado los datos por \"Hotel_Name\" y he calculado la media de la \"Average_Score\". \nHe proseguido con el comando \"orderBy\" para ordenar en orden descendente los hoteles por según sus medias (para conseguir los hoteles con la mayor puntuación). \nFinalmente he limitado los resultados a 10 para conseguir así lo 10 hoteles con mayor puntuación media sin incluir los hoteles que tengan una puntuación por encima de Good."],"metadata":{}},{"cell_type":"code","source":["df_spark_sql_train.filter('(score_string <> \"Perfect\") and (score_string <> \"Excellent\")').select('Hotel_Name',\"Average_Score\").groupBy('Hotel_Name').avg(\"Average_Score\").orderBy(\"avg(Average_Score)\",ascending=False).limit(10).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+------------------+\n          Hotel_Name|avg(Average_Score)|\n+--------------------+------------------+\nGreat Northern Ho...|  8.90000000000006|\nThe Marylebone Hotel| 8.900000000000059|\n     Starhotels Echo| 8.900000000000059|\nNegresco Princess...| 8.900000000000057|\nMajestic Hotel Sp...| 8.900000000000052|\nHotel Okura Amste...|  8.90000000000005|\n   K K Hotel Picasso| 8.900000000000048|\nCol n Hotel Barce...| 8.900000000000045|\nSt Ermin s Hotel ...| 8.900000000000045|\nHotel Saint Peter...| 8.900000000000043|\n+--------------------+------------------+\n\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["# Machine Learning en Apache Spark: Spark MLLib y Spark ML #"],"metadata":{}},{"cell_type":"markdown","source":["## Clasificación Supervisada: Árboles de decisión ##"],"metadata":{}},{"cell_type":"markdown","source":["### Ejercicio 6.1: Volver a observar todas las columnas del dataframe, para identificar las que sean categóricas. ###\nAplico el mismo codigo que usé en el primer ejercicio pero ahora con el dataframe \"df_spark_sql_train\" y veo que efectivamente existen veriables categoricas. \nPara efectuar los procesos de Machine learning deberemos eliminarlas o transformarlas en variables numéricas."],"metadata":{}},{"cell_type":"code","source":["for i in df_spark_sql_train.dtypes:\n  print(i)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;Hotel_Address&#39;, &#39;string&#39;)\n(&#39;Additional_Number_of_Scoring&#39;, &#39;int&#39;)\n(&#39;Review_Date&#39;, &#39;string&#39;)\n(&#39;Average_Score&#39;, &#39;double&#39;)\n(&#39;Hotel_Name&#39;, &#39;string&#39;)\n(&#39;Reviewer_Nationality&#39;, &#39;string&#39;)\n(&#39;Negative_Review&#39;, &#39;string&#39;)\n(&#39;Review_Total_Negative_Word_Counts&#39;, &#39;int&#39;)\n(&#39;Total_Number_of_Reviews&#39;, &#39;int&#39;)\n(&#39;Positive_Review&#39;, &#39;string&#39;)\n(&#39;Review_Total_Positive_Word_Counts&#39;, &#39;int&#39;)\n(&#39;Total_Number_of_Reviews_Reviewer_Has_Given&#39;, &#39;int&#39;)\n(&#39;Reviewer_Score&#39;, &#39;double&#39;)\n(&#39;Tags&#39;, &#39;string&#39;)\n(&#39;days_since_review&#39;, &#39;int&#39;)\n(&#39;lat&#39;, &#39;float&#39;)\n(&#39;lng&#39;, &#39;float&#39;)\n(&#39;score_string&#39;, &#39;string&#39;)\n(&#39;score_evaluation&#39;, &#39;int&#39;)\n</div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["### Ejercicio 6.2: Eliminar, de los dataframes df_spark_sql_train y df_spark_sql test, las variables 'Hotel_Address', 'Hotel_Name', 'Tags', 'Positive Review', 'Negative_Review' y 'score_string'. Llamarlos: df_DT_train y df_DT_test. ### \n\nOptamos para eliminar las variables categoricas, menos \"Review_Date\" y \"Review_Nationality\" que transformaremos en variables numéricas."],"metadata":{}},{"cell_type":"code","source":["df_DT_train = df_spark_sql_train.drop(\"Hotel_Address\").drop(\"Hotel_Name\")\\\n  .drop(\"Tags\").drop(\"Positive_Review\").drop(\"Negative_Review\").drop(\"score_string\")\ndf_DT_test = df_spark_sql_test.drop(\"Hotel_Address\").drop(\"Hotel_Name\")\\\n  .drop(\"Tags\").drop(\"Positive_Review\").drop(\"Negative_Review\").drop(\"score_string\")\n\nfor i in df_DT_train.dtypes:\n  print(i)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;Additional_Number_of_Scoring&#39;, &#39;int&#39;)\n(&#39;Review_Date&#39;, &#39;string&#39;)\n(&#39;Average_Score&#39;, &#39;double&#39;)\n(&#39;Reviewer_Nationality&#39;, &#39;string&#39;)\n(&#39;Review_Total_Negative_Word_Counts&#39;, &#39;int&#39;)\n(&#39;Total_Number_of_Reviews&#39;, &#39;int&#39;)\n(&#39;Review_Total_Positive_Word_Counts&#39;, &#39;int&#39;)\n(&#39;Total_Number_of_Reviews_Reviewer_Has_Given&#39;, &#39;int&#39;)\n(&#39;Reviewer_Score&#39;, &#39;double&#39;)\n(&#39;days_since_review&#39;, &#39;int&#39;)\n(&#39;lat&#39;, &#39;float&#39;)\n(&#39;lng&#39;, &#39;float&#39;)\n(&#39;score_evaluation&#39;, &#39;int&#39;)\n</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["### Ejercicio 7: Para cada columa restante que sea String ('Review_Date' y 'Review_Nationality'), aplicar un StringIndexer(), devolviendo como resultado la misma columna, pero con su nombre acabando en _index. Sobreescribir ambos dataframes.  ###\n\nEn este ejercicio convierto los strings en numeros. Lo consigo pasando las columnas que continen caracteres por la función \"StringIndexer\", indicandole a dicha función la columna que quiero convertir y el nombre de la columna resultante. \nCon el \"fit\" coloco el dataframe dentro del cual se buscará la columna que quiero transformar para hacer los calculos pertinentes. Con el \"transform\" confirmo que quiero transformar los datos, generando así la columna \"output\". \n\nEste procedimiento lo aplico para las columnas de train y de test para las dos variables citadas en este ejercicio ('Review_Date' y 'Review_Nationality')"],"metadata":{}},{"cell_type":"code","source":["\nfrom pyspark.ml.feature import StringIndexer\n\ndf_DT_train = StringIndexer(inputCol=\"Review_Date\", outputCol=\"Review_Date_index\").fit(df_DT_train).transform(df_DT_train)\ndf_DT_train = StringIndexer(inputCol='Reviewer_Nationality', outputCol=\"Reviewer_Nationality_index\").fit(df_DT_train).transform(df_DT_train)\ndf_DT_test = StringIndexer(inputCol=\"Review_Date\", outputCol=\"Review_Date_index\").fit(df_DT_test).transform(df_DT_test)\ndf_DT_test = StringIndexer(inputCol='Reviewer_Nationality', outputCol=\"Reviewer_Nationality_index\").fit(df_DT_test).transform(df_DT_test)\n\n\nfor i in df_DT_train.dtypes:\n  print(i)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;Additional_Number_of_Scoring&#39;, &#39;int&#39;)\n(&#39;Review_Date&#39;, &#39;string&#39;)\n(&#39;Average_Score&#39;, &#39;double&#39;)\n(&#39;Reviewer_Nationality&#39;, &#39;string&#39;)\n(&#39;Review_Total_Negative_Word_Counts&#39;, &#39;int&#39;)\n(&#39;Total_Number_of_Reviews&#39;, &#39;int&#39;)\n(&#39;Review_Total_Positive_Word_Counts&#39;, &#39;int&#39;)\n(&#39;Total_Number_of_Reviews_Reviewer_Has_Given&#39;, &#39;int&#39;)\n(&#39;Reviewer_Score&#39;, &#39;double&#39;)\n(&#39;days_since_review&#39;, &#39;int&#39;)\n(&#39;lat&#39;, &#39;float&#39;)\n(&#39;lng&#39;, &#39;float&#39;)\n(&#39;score_evaluation&#39;, &#39;int&#39;)\n(&#39;Review_Date_index&#39;, &#39;double&#39;)\n(&#39;Reviewer_Nationality_index&#39;, &#39;double&#39;)\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["### Ejercicio 8: Aplicar VectorAssembler() sobre las columnas que no son ni las dos anteriores, ni la columna 'score_evaluation', devolviendo una columna llamada 'features'. Llamar al resultado DT_vector_assembler. ###\n\nEn este ejercicio creo el Vector Assembler que dipositará toda la información que existe en el dataframe en un solo vector. \nEste paso es necesario ya que es la forma en que Spark ML espera obtener la información. \n\nDado que hemos creado las variables \"Review_Date_index\" y \"Reviewer_Nationality_index\" le indicamos (mediante el comando drop) que en el vector no incluya las varaibles\n\"Review_Date\" y \"Reviewer_Nationality\". \nAdemás, dado que \"score_evaluation\" es la columna que vamos a predecir, tampoco la incluimos.\n\nFinalmente, le indico que el output (el vector que se creará) se le dé el nombre de \"features\"."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nLR_vector_assembler = VectorAssembler(\\\n  inputCols=df_DT_train.drop(\"Review_Date\").drop(\"Reviewer_Nationality\").drop(\"score_evaluation\").columns,\\\n  outputCol=\"features\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["### Ejercicio 9: Aplicar el transformador sobre ambos dataframes. ###\nAhora que ya se ha creado el \"VectorAssembler\" lo aplico con el \"transform\" y le doy los datos que se deben transfomar en vector, en ete caso el df_DT_train y el df_DT_test"],"metadata":{}},{"cell_type":"code","source":["df_DT_train = LR_vector_assembler.transform(df_DT_train)\ndf_DT_test = LR_vector_assembler.transform(df_DT_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["### Ejercicio 10: Inicializar el modelo de árbol de decisión, entrenarlo y aplicarlo sobre los datos de test. ###\n* Modelo: DecisionTreeClassifier:\n  * Label: score_evaluation.\n  * Features: features.\n  * maxBins: 1000\n  * maxDepth: 1\n  \nDado que SparkMLLib requiere que hayamos creado los RDD y en este caso no lo hemos hecho, voy a utilizar las librerias de Spark ML. \n\nVoy a empezar importando las librerias necesarias.\n\nA continuación voy a crear el modelo especificando el \"label\", el nombre de la columna con la que entrenaremos el modelo, así como la profundidad del modelo y los bins. \nFinalmente entreno el modelo pasando los datos del dataframe de entrenamiento.\n\nTermino el ejercicio 10 aplicando el modelo entrenado a los datos que tengo guardados para el test."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier(labelCol=\"score_evaluation\", featuresCol=\"features\",maxDepth=1, maxBins=1000).fit(df_DT_train)\n\nprediction = model.transform(df_DT_test)\nprint(prediction)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">DataFrame[Additional_Number_of_Scoring: int, Review_Date: string, Average_Score: double, Reviewer_Nationality: string, Review_Total_Negative_Word_Counts: int, Total_Number_of_Reviews: int, Review_Total_Positive_Word_Counts: int, Total_Number_of_Reviews_Reviewer_Has_Given: int, Reviewer_Score: double, days_since_review: int, lat: float, lng: float, score_evaluation: int, Review_Date_index: double, Reviewer_Nationality_index: double, features: vector, rawPrediction: vector, probability: vector, prediction: double]\n</div>"]}}],"execution_count":37},{"cell_type":"markdown","source":["### Ejercicio 11: Evaluar el modelo aplicándole un clasificador multiclase. Calcular la métrica 'accuracy', y conseguir el complementario para calcular el error. ###\n* Evaluador: MulticlassClassificationEvaluator\n  * Label: score_evaluation.\n  * Prediction: prediction.\n  * MetricName: accuracy.\n\nVoy a empezar este ejercicio importando las librerias que necesito, a continuación, creo el evaluador donde le indico que quiero realizar una predicción con \"score_evaluation\" y que estoy interesado en la métrica \"accuracy\".\n\nPosteriormente al evaluador le paso la variable \"prediction\" que he conseguido en el ejercicio anterior para que calcule la \"accuracy\". \n\nTermino este ejercicio restando \"1-accuracy\" para saber el error existente."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"score_evaluation\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(prediction)\nprint(accuracy)\nprint(\" Error = %g \" % (1.0 - accuracy))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.9887140640578633\n Error = 0.0112859 \n</div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["## Spark ML: Pipelines ##"],"metadata":{}},{"cell_type":"markdown","source":["### Pipelines: Árboles de Decisión ###\nCon el mismo concepto que con el KMeans, se va a diseñar el flujo para los árboles de decisión. Primero hay que aplicar los cambios de preprocesamiento vistos anteriormente al DataFrame inicial para preparalo."],"metadata":{}},{"cell_type":"markdown","source":["### Ejercicio 12: Eliminar, de los dataframes df_spark_sql_train y df_spark_sql test, las variables 'Hotel_Address', 'Hotel_Name', 'Tags', 'Positive Review', 'Negative_Review' y 'score_string'. Llamarlos: df_DT_train y df_DT_test. ### \n\nEn este ejercicio aplico el mismo procedimiento que en el ejercicio 7."],"metadata":{}},{"cell_type":"code","source":["df_DT_train = df_spark_sql_train.drop(\"Hotel_Address\").drop(\"Hotel_Name\")\\\n  .drop(\"Tags\").drop(\"Positive_Review\").drop(\"Negative_Review\").drop(\"score_string\")\ndf_DT_test = df_spark_sql_test.drop(\"Hotel_Address\").drop(\"Hotel_Name\")\\\n  .drop(\"Tags\").drop(\"Positive_Review\").drop(\"Negative_Review\").drop(\"score_string\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"markdown","source":["Después se diseña el flujo para este modelo, el cual será:\n\n** StringIndexer --> VectorAssembler --> Decission Tree (Inicialización) --> Decission Tree (Entrenamiento) --> Modelo Decission Tree entrenado **"],"metadata":{}},{"cell_type":"markdown","source":["### Ejercicio 13: Recoger una lista con todos los StringIndexer a aplicar, y llamarla DT_string_indexers ###\n En lugar de sobreescribir cada vez el dataframe, crear una lista, y con el método 'append', se irán añadiendo todos los StringIndexers().\n \n Empiezo con la creación de la Pipeline. \n En este caso le digo que si el tipo de la columna es igual a \"string\" que cree una variable \"StringIndexer\" que se guarda en la variable \"DT_string_indexers\" para poder montar correctamente la pipeline."],"metadata":{}},{"cell_type":"code","source":["DT_string_indexers = []\nfor dtype in df_DT_train.dtypes:\n  if dtype[1] == \"string\":\n    DT_string_indexers.append(StringIndexer(inputCol=dtype[0], outputCol=dtype[0]+\"_index\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["### Ejercicio 14: Guardar en la variable 'DT_vector_assembler' la aplicación del mismo VectorAssembler() del ejercicio 8. ###\nHago lo mismo que en el ejercicio anterior, para montar la pipeline, creo una variable que contiene el \"VectorAssembler\" guardando el resultado en la variable \"D_vector_assembler\""],"metadata":{}},{"cell_type":"code","source":["DT_vector_assembler = VectorAssembler(\\\n  inputCols=df_DT_train.drop(\"Review_Date\").drop(\"Reviewer_Nationality\").drop(\"score_evaluation\").columns,\\\n  outputCol=\"features\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":48},{"cell_type":"markdown","source":["### Ejercicio 15: Crear una lista con el mombre de DT_pipeline_stages, y añadirle la lista de StringIndexers y el VectorAssembler (en este orden) ###\n\nEn este ejercicio simplemente diposito la información de las variables que he creado en los dos últimos ejercicios en la \"DT_pipeline_stages\"."],"metadata":{}},{"cell_type":"code","source":["DT_pipeline_stages = [str_indexer for str_indexer in DT_string_indexers]\nDT_pipeline_stages.append(DT_vector_assembler)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"markdown","source":["### Ejercicio 16: Inicializar el modelo de árbol de decisión (mismas especificaciones que en el ej. 10), y añadirlo a la lista de pasos 'DT_pipeline_stages' ###\n\nDentro de la pipeline también estará el modelo creado. Esta vez, no lo entrenamos (como sí que hicimos en le ejercicio 10), ya que lo haremos en el último paso."],"metadata":{}},{"cell_type":"code","source":["model = DecisionTreeClassifier(labelCol=\"score_evaluation\", featuresCol=\"features\",maxDepth=1, maxBins=1000)\nDT_pipeline_stages.append(model)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"markdown","source":["### Ejercicio 17: Diseñar el Pipeline y aplicarlo sobre los datos de Train, llamándolo 'DT_pipeline_model' ###\nEn este ejercicio pasamos toda la pipeline creada por la función Pipeline. Esto crea un objeto que aplicaremos en el próximo ejercicio."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nDT_pipeline = Pipeline(stages=DT_pipeline_stages)\nprint(DT_pipeline)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pipeline_1c30159ce883\n</div>"]}}],"execution_count":54},{"cell_type":"markdown","source":["### Ejercicio 18: Aplicar el modelo resultante sobre los datos de test y evaluarlo al igual que se hizo en el ej. 11 ###\n\nFinalmente, introduzco los datos a la pipeline, esta, hará todos pasos que hemos dipositado dentro de la misma, finalizando con el proceso del \"training\" del modelo. \n\nTermino el ejercicio calculando la \"accuracy\" del modelo con los datos de dataframe del test."],"metadata":{}},{"cell_type":"code","source":["DT_pipeline_model = DT_pipeline.fit(df_DT_train)\n\nprediction = DT_pipeline_model.transform(df_DT_test)\nevaluator = MulticlassClassificationEvaluator(\n    labelCol=\"score_evaluation\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(prediction)\nprint(accuracy)\nprint(\" Error = %g \" % (1.0 - accuracy))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0.9887140640578633\n Error = 0.0112859 \n</div>"]}}],"execution_count":56}],"metadata":{"name":"AnaliticaEscalablePySparkEjercicios","notebookId":3510895540622380},"nbformat":4,"nbformat_minor":0}
