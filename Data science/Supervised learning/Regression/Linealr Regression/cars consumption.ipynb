{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case I will create a model to predict the consumption of a car based on its characteristics\n",
    "-cylinders\n",
    "-displacement\n",
    "-horsepower\n",
    "-weight\n",
    "-acceleration\n",
    "-model_year\n",
    "-origin (It defines which country the car comes from) \n",
    "-mpg (this is the actual consume of the car)\n",
    "Crea un modelo con él para que se pueda estimar el consumo de un vehículo a partir del resto de las variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to predict a numeric variable, I will build the model using Linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cylinders  displacement  horsepower  weight  acceleration  model_year  \\\n",
      "0            8         307.0       130.0  3504.0          12.0          70   \n",
      "1            8         350.0       165.0  3693.0          11.5          70   \n",
      "2            8         318.0       150.0  3436.0          11.0          70   \n",
      "3            8         304.0       150.0  3433.0          12.0          70   \n",
      "4            8         302.0       140.0  3449.0          10.5          70   \n",
      "..         ...           ...         ...     ...           ...         ...   \n",
      "387          4         140.0        86.0  2790.0          15.6          82   \n",
      "388          4          97.0        52.0  2130.0          24.6          82   \n",
      "389          4         135.0        84.0  2295.0          11.6          82   \n",
      "390          4         120.0        79.0  2625.0          18.6          82   \n",
      "391          4         119.0        82.0  2720.0          19.4          82   \n",
      "\n",
      "     origin   mpg  \n",
      "0         1  18.0  \n",
      "1         1  15.0  \n",
      "2         1  18.0  \n",
      "3         1  16.0  \n",
      "4         1  17.0  \n",
      "..      ...   ...  \n",
      "387       1  27.0  \n",
      "388       2  44.0  \n",
      "389       1  32.0  \n",
      "390       1  28.0  \n",
      "391       1  31.0  \n",
      "\n",
      "[392 rows x 8 columns]\n",
      "Index(['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration',\n",
      "       'model_year', 'origin'],\n",
      "      dtype='object')\n",
      "   cylinders  displacement  horsepower  weight  acceleration  model_year  \\\n",
      "0          8         307.0       130.0  3504.0          12.0          70   \n",
      "1          8         350.0       165.0  3693.0          11.5          70   \n",
      "2          8         318.0       150.0  3436.0          11.0          70   \n",
      "3          8         304.0       150.0  3433.0          12.0          70   \n",
      "4          8         302.0       140.0  3449.0          10.5          70   \n",
      "\n",
      "   origin  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n"
     ]
    }
   ],
   "source": [
    "#I will start importing the libraries and data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv(\"auto.csv\")\n",
    "print(data)\n",
    "y=data.mpg\n",
    "data=data.drop([\"mpg\"],axis=1)\n",
    "\n",
    "#I will take a look at the data\n",
    "print(data.columns)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy variables: \n",
    "\n",
    "\n",
    "With the \"head\" function I have been able to see that \"cylinders\" and the \"origin\" are two numerical variables that should be categorical, since they are just defining different classes.\n",
    "\n",
    "For example, the variable \"cylinders\" determines if a car corresponds to the group of cars with 8 cylinders, with 4 cylinders... To have the information as a category is much more useful than making the model to calculate a \"weight\" to multiply for the number of cylinders the car has.\n",
    "\n",
    "I will now proceed to examine how many unique numbers are in these two variables and then I will transform then in dummy variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 4 6 3 5]\n",
      "[1 3 2]\n"
     ]
    }
   ],
   "source": [
    "print(data[\"cylinders\"].unique())\n",
    "print(data[\"origin\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([3, 4, 5, 6, 8], dtype=int64), array([1, 2, 3], dtype=int64)]\n",
      "   4 cil  5 cil  6 cil  8 cil  origen 2  origen 3\n",
      "0    0.0    0.0    0.0    1.0       0.0       0.0\n",
      "1    0.0    0.0    0.0    1.0       0.0       0.0\n",
      "2    0.0    0.0    0.0    1.0       0.0       0.0\n",
      "3    0.0    0.0    0.0    1.0       0.0       0.0\n",
      "4    0.0    0.0    0.0    1.0       0.0       0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#I will transform the variables in dummies with the function \"OneHotEncoder\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False) \n",
    "\n",
    "#Now I will introduce the variables I want to transform to the encoder that I have created. \n",
    "subdata=pd.DataFrame(ohe.fit_transform(data[['cylinders',\"origin\"]]))\n",
    "print(ohe.categories_) #with the \"categories_\" I can check how the encoder has sorted the different categories \n",
    "    #[array([3, 4, 5, 6, 8], dtype=int64), array([1, 2, 3], dtype=int64)] #firs the cylinders with the following order \n",
    "    #3, 4, 5, 6, 8 and then the origins in this order 1,2,3\n",
    "    \n",
    "    \n",
    "#Since the encoder has removes the name of the variables, I will now change the name of the columns.\n",
    "subdata.columns=[\"3 cil\", \"4 cil\", \"5 cil\", \"6 cil\", \"8 cil\",\"origen 1\", \"origen 2\", \"origen 3\"]\n",
    "\n",
    "\n",
    "#Now I will delete one column of each of the variables that I have transformed into dummies. \n",
    "\n",
    "#I do this because otherwise I the model will be obtaining the same information two times and thus it will only make the \n",
    "#prediction worst.\n",
    "\n",
    "\n",
    "subdata=subdata.drop([\"3 cil\",\"origen 1\"],axis=1) \n",
    "print(subdata.head())\n",
    "\n",
    "#Now I will drop the two variables that I encoded that are in the \"data\" dataset,\n",
    "#I do this because I will concatenate the \"data\" and the \"subdata\" dataframes. \n",
    "#If I didn't delete these two variables, then, again, I would be giving the same information two times to the model.\n",
    "\n",
    "data=data.drop([\"cylinders\",\"origin\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data standardization\n",
    "\n",
    "Before I proceed to concatenate the dataframes, I will standardize the information that is contained in the \"data\" dataframe. \n",
    "\n",
    "I'm doing this step because all the variables show different dimensions. \n",
    "For example, the variable \"weight\" has mean of 2977 and the variable \"model_year\" has a mean of 75. \n",
    "These two variables are not proportional and if the data was not scaled, then the model would give more importance \n",
    "to the variable with bigger numbers.\n",
    "\n",
    "I'm applying this procedure BEFORE concatenating the datasets \"data\" and \"subdata\" because the data-science community it is not clear whether the dummy variables should be standardized or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4 cil  5 cil  6 cil  8 cil  origen 2  origen 3  displacement  horsepower  \\\n",
      "0    0.0    0.0    0.0    1.0       0.0       0.0      1.077290    0.664133   \n",
      "1    0.0    0.0    0.0    1.0       0.0       0.0      1.488732    1.574594   \n",
      "2    0.0    0.0    0.0    1.0       0.0       0.0      1.182542    1.184397   \n",
      "3    0.0    0.0    0.0    1.0       0.0       0.0      1.048584    1.184397   \n",
      "4    0.0    0.0    0.0    1.0       0.0       0.0      1.029447    0.924265   \n",
      "\n",
      "     weight  acceleration  model_year  \n",
      "0  0.620540     -1.285258   -1.625315  \n",
      "1  0.843334     -1.466724   -1.625315  \n",
      "2  0.540382     -1.648189   -1.625315  \n",
      "3  0.536845     -1.285258   -1.625315  \n",
      "4  0.555706     -1.829655   -1.625315  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "names=data.columns #I get the number of the columns, because the scaler will delete the names of the columns \n",
    "scal=StandardScaler()#I create the scaler\n",
    "data=pd.DataFrame(scal.fit_transform(data)) #I apply the scaler\n",
    "data.columns=names #I introduce the original names to the different columns\n",
    "\n",
    "#I concatenate the two dataframes.\n",
    "data=pd.concat([subdata, data],axis=1)\n",
    "\n",
    "#Finally I check if everything went as expected. \n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward selection\n",
    "\n",
    "Now I will select the variables that should be part of the lineal regression, using the \"forward selection\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['4 cil', '5 cil', '6 cil', '8 cil', 'origen 2', 'origen 3',\n",
      "       'displacement', 'horsepower', 'weight', 'acceleration', 'model_year'],\n",
      "      dtype='object')\n",
      "In the step 0 the following variable got introduced weight with an error of 4.3216451262707\n",
      "In the step 1 the following variable got introduced model_year with an error of 3.414013752452535\n",
      "In the step 2 the following variable got introduced 6 cil with an error of 3.2557095011977686\n",
      "In the step 3 the following variable got introduced horsepower with an error of 3.2249458938886733\n",
      "In the step 4 the following variable got introduced origen 3 with an error of 3.194371955452919\n",
      "In the step 5 the following variable got introduced origen 2 with an error of 3.169778591843068\n",
      "In the step 6 the following variable got introduced displacement with an error of 3.1286746856188383\n",
      "In the step 7 the following variable got introduced 4 cil with an error of 3.0860767239734743\n",
      "In the step 8 the following variable got introduced 5 cil with an error of 3.0740159888256717\n",
      "In the step 9 the following variable got introduced 8 cil with an error of 3.0502013386421525\n",
      "In the step 10 the following variable got introduced acceleration with an error of 3.049888434594145\n",
      "['weight', 'model_year', '6 cil', 'horsepower', 'origen 3', 'origen 2', 'displacement', '4 cil', '5 cil', '8 cil', 'acceleration']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "feature_order =  []\n",
    "feature_error = []\n",
    "\n",
    "features=data.columns\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "for i in range(len(features)):\n",
    "    idx_try = [val for val in range(len(features)) if val not in feature_order]\n",
    "    iter_error = []\n",
    "\n",
    "    for i_try in idx_try:\n",
    "        useRow = feature_order[:]\n",
    "        useRow.append(i_try)\n",
    "\n",
    "        use = data[data.columns[useRow]]\n",
    "\n",
    "        model.fit(use, y)\n",
    "        rmsError = np.linalg.norm((y - model.predict(use)), 2)/np.sqrt(len(y))\n",
    "        iter_error.append(rmsError)\n",
    "    \n",
    "    pos_best = np.argmin(iter_error)\n",
    "    feature_order.append(idx_try[pos_best])\n",
    "    feature_error.append(iter_error[pos_best])\n",
    "\n",
    "features_list=[]\n",
    "for i in range(len(features)):\n",
    "    print(\"In the step\", i, \"the following variable got introduced\", \n",
    "        features[feature_order[i]], \"with an error of\", feature_error[i])\n",
    "    features_list.append(str(features[feature_order[i]]))\n",
    "print(features_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the error that show the different models, I can conclude that all the varaibles add usefull information to the model but the \"acceleration\" one. This last one makes the model worst and thus, it must be deleted.\n",
    "\n",
    "In order to be sure about this conclusion I will also calculate the adjusted R^2 so I can compare the different models. \n",
    "\n",
    "I will calculate the adjusted R^2 of 4 models, those that seem to be more significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 modelo 1: 0.8346437869839413\n",
      "R^2 Ajustada: 0.8320668070408339\n",
      "\n",
      "R^2 modelo 2: 0.8444840614198668\n",
      "R^2 Ajustada: 0.8408200733381359\n",
      "\n",
      "R^2 modelo 3: 0.8468843168566745\n",
      "R^2 Ajustada: 0.8428655325222041\n",
      "\n",
      "R^2 modelo 4: 0.8469157299040813\n",
      "R^2 Ajustada: 0.8424843431381468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This model predict a good part of the variance but still there is a big part that can't be predicted.\n",
    "\n",
    "\n",
    "x=data.loc[:,[\"weight\",\"model_year\",\"6 cil\",\"horsepower\",\"origen 3\",\"origen 2\"]]\n",
    "model=LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(\"R^2 modelo 1:\",model.score(x,y))\n",
    "\n",
    "R=model.score(x,y)\n",
    "adj_r2 = (1 - (1 - R) * ((len(x) - 1) / \n",
    "          (len(x) - len(x.columns) - 1))) \n",
    "print(\"R^2 Ajustada:\", adj_r2) \n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#This second model is better than the last one, it shows a better R^2 and adjusted R^2\n",
    "x=data.loc[:,[\"weight\",\"model_year\",\"6 cil\",\"horsepower\",\"origen 3\",\"origen 2\",\"displacement\",\"4 cil\",\"5 cil\"]]\n",
    "model=LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(\"R^2 modelo 2:\",model.score(x,y))\n",
    "R=model.score(x,y)\n",
    "\n",
    "adj_r2 = (1 - (1 - R) * ((len(x) - 1) / \n",
    "          (len(x) - len(x.columns) - 1))) \n",
    "print(\"R^2 Ajustada:\", adj_r2) \n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#This even better than the last one.\n",
    "x=data.loc[:,[\"weight\",\"model_year\",\"6 cil\",\"horsepower\",\"origen 3\",\"origen 2\",\"displacement\",\"4 cil\",\"5 cil\",\"8 cil\"]]\n",
    "model=LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(\"R^2 modelo 3:\",model.score(x,y))\n",
    "R=model.score(x,y)\n",
    "\n",
    "adj_r2 = (1 - (1 - R) * ((len(x) - 1) / \n",
    "          (len(x) - len(x.columns) - 1))) \n",
    "print(\"R^2 Ajustada:\", adj_r2) \n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#This forth model, even though it has a greater R^2 the adjusted R^2 gets worst. \n",
    "#I can conclude then that this model is worse than the previous one.\n",
    "\n",
    "\n",
    "x=data.loc[:,[\"weight\",\"model_year\",\"6 cil\",\"horsepower\",\"origen 3\",\"origen 2\",\"displacement\",\"4 cil\",\"5 cil\",\"8 cil\",\"acceleration\"]]\n",
    "model=LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(\"R^2 modelo 4:\",model.score(x,y))\n",
    "R=model.score(x,y)\n",
    "\n",
    "adj_r2 = (1 - (1 - R) * ((len(x) - 1) / \n",
    "          (len(x) - len(x.columns) - 1))) \n",
    "print(\"R^2 Ajustada:\",adj_r2)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 modelo 3: 0.8468843168566745\n"
     ]
    }
   ],
   "source": [
    "#After considering this 4 models I can conclude that the best model is the following one.\n",
    "\n",
    "x=data.loc[:,[\"weight\",\"model_year\",\"6 cil\",\"horsepower\",\"origen 3\",\"origen 2\",\"displacement\",\"4 cil\",\"5 cil\",\"8 cil\"]]\n",
    "model=LinearRegression().fit(x,y)\n",
    "print(\"R^2 modelo 3:\",model.score(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "\n",
    "Now I will check if the model is overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 with training data:  0.8445968083568386\n",
      "R^2 with test data:  0.8479074244491961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#I start dividing the dataset in training and testing data.\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1)\n",
    "\n",
    "#I'm now training the model with the training data\n",
    "model=LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "predic_train=model.predict(x_train)\n",
    "predic_test=model.predict(x_test)\n",
    "\n",
    "print(\"R^2 with training data: \",model.score(x_train,y_train))\n",
    "print(\"R^2 with test data: \",model.score(x_test,y_test))\n",
    "#The results don't show that the model is not Overfitted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
